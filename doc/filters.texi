@chapter Video Filters
@c man begin VIDEO FILTERS

When you configure your FFmpeg build, you can disable any of the
existing filters using --disable-filters.
The configure output will show the video filters included in your
build.

Below is a description of the currently available video filters.

@section crop

Crop the input video to @var{x}:@var{y}:@var{width}:@var{height}.

@example
./ffmpeg -i in.avi -vf "crop=0:0:0:240" out.avi
@end example

@var{x} and @var{y} specify the position of the top-left corner of the
output (non-cropped) area.

The default value of @var{x} and @var{y} is 0.

The @var{width} and @var{height} parameters specify the width and height
of the output (non-cropped) area.

A value of 0 is interpreted as the maximum possible size contained in
the area delimited by the top-left corner at position x:y.

For example the parameters:

@example
"crop=100:100:0:0"
@end example

will delimit the rectangle with the top-left corner placed at position
100:100 and the right-bottom corner corresponding to the right-bottom
corner of the input image.

The default value of @var{width} and @var{height} is 0.

@section drawbox

@example
./ffmpeg -i in.avi -vf "drawbox=10:20:200:60:red" out.avi
@end example

Draw a box with @var{x}:@var{y}:@var{width}:@var{height}:@var{color}
dimensions in a chosen color.

@section drawtext

Draw text string or text from specified file on top of video using the
libfreetype library.
The filter also recognizes strftime() sequences in the provided text and
expands them accordingly. Check the documentation of strftime().

To enable compilation of this filter you need to configure FFmpeg with
--enable-libfreetype.

The filter accepts parameters as a list of @var{key}=@var{value} pairs,
separated by ":".

The description of the accepted parameters follows.

@table @option
@item fontfile

The font file to be used for drawing text. Path must be included.
This parameter is mandatory.

@item text

The text string to be drawn.
This parameter is mandatory if no file is specified.

@item textfile

A text file containing text to be drawn. Max of 1024 characters are
read from the file.

This parameter is mandatory if no text string is specified.

If both text and textfile are specified, an error is thrown.

@item x, y

The offsets where text will be drawn within the video frame.
Relative to the top/left border of the output image.

The default value of @var{x} and @var{y} is 0.

@item fontsize

The font size to be used for drawing text.

The default value of @var{size} is 16.

@item fgcolor

The foreground color to be used for drawing text.
Either a string (e.g. ``red'') or in 0xRRGGBB[AA] format
(e.g. ``0xff000033''), possibly followed by an alpha specifier.

The default value of @var{fgcolor} is black.

@item bgcolor

The background color to be used for drawing box around text or drawing
text outline based on option selected.
Either a string (e.g. ``yellow'') or in 0xRRGGBB[AA] format
(e.g. ``0xff00ff''), possibly followed by an alpha specifier.

The default value of @var{bgcolor} is white.

@item box

Used to draw a box around text using background color.
Value should be either 1 (enable) or 0 (disable).

The default value of @var{box} is 0.

@item outline

Used to draw an outline around text using background color.
Value should be either 1 (enable) or 0 (disable).

The default value of @var{outline} is 0.

@end table

@example
drawtext="fontfile=FreeSerif.ttf: text='Test Text': x=100: y=50: fontsize=24:
          fgcolor=yellow@@0.2: bgcolor=red@@0.2: box=1"
@end example

Draw 'Test Text' with font FreeSerif of size 24 at (100,50), text color is yellow,
background color is red, draw a box around text. Both the text and the
box have an opacity of 20%.

Note that the double quotes are not necessary if spaces are not used within
the parameter list.

@section fifo

@example
./ffmpeg -i in.avi -vf "fifo" out.avi
@end example

@section format

Convert the input video to one of the specified pixel formats.
Libavfilter will try to pick one that is supported for the input to
the next filter.

The filter accepts a list of pixel format names, separated by ``:'',
for example ``yuv420p:monow:rgb24''.

The following command:

@example
./ffmpeg -i in.avi -vf "format=yuv420p" out.avi
@end example

will convert the input video to the format ``yuv420p''.

@section fps

@example
./ffmpeg -i in.avi -vf "fps=30000:1001" out.avi
@end example

Modifies the framerate of the input video to a chosen one.

@section hflip

@example
./ffmpeg -i in.avi -vf "hflip" out.avi
@end example

Flip the video horizontally.

@section negate

@example
./ffmpeg -i in.avi -vf "negate" out.avi
@end example

Convert a video to its negative.
  
@section noformat

Force libavfilter not to use any of the specified pixel formats for the
input to the next filter.

The filter accepts a list of pixel format names, separated by ``:'',
for example ``yuv420p:monow:rgb24''.

The following command:

@example
./ffmpeg -i in.avi -vf "noformat=yuv420p, vflip" out.avi
@end example

will make libavfilter use a format different from ``yuv420p'' for the
input to the vflip filter.

@section null

Pass the source unchanged to the output.

@section overlay

Overlay one video on top of another (see the example in the introduction
section).
Be aware that frames are taken
from each input video in timestamp order, hence, if their initial
timestamps differ, it is a a good idea to pass the two
inputs through a @var{setpts=PTS-STARTPTS} filter to have them
begin in the same zero timestamp, as it does the example for
the @var{movie} filter.

Parameters to the filter are separated by a colon. The first parameter
is the x coordinate of the overlay, the second parameter is the y
coordinate. The parameters need not be constant expressions, but may
be expressions containing the names @var{main_w}, @var{main_h},
@var{overlay_w} and @var{overlay_h}, for the size of the first and second
input video, respectively. For example,
@example
overlay=main_w-overlay_w-10:main_h-overlay_h-10
@end example
can be used to draw the overlay at 10 pixels from the bottom right
corner of the main video.

The filter accepts a third optional parameter, if set to a value
different than 0, it will alpha-blend the overlayed video on top of
the first one.

This can be used in particular for performing watermarking effects, or
for adding a logo on top of the input video.

For example, the following command will insert a transparent PNG
logo in the bottom left corner of the input video:
@example
movie=0:png:logo.png [logo]; [in][logo] overlay=10:main_h-overlay_h-10:1 [out]
@end example

Notice the last parameter to overlay ":1" - this enables alpha blending.

The following example will insert 2 different transparent PNG
logos (second logo on bottom right corner):
@example
movie=0:png:logo1.png [logo1];
movie=0:png:logo2.png [logo2];
[in][logo1] overlay=10:main_h-overlay_h-10:1 [in+logo1];
[in+logo1][logo2] overlay=main_w-overlay_w-10:main_h-overlay_h-10:1 [out]
@end example

You could chain and add more overlays this way but the efficiency of
such approach is yet to be tested.

@section pad

Add paddings to the input image, and places the original input at the
given coordinates @var{x}, @var{y}.

It accepts the following parameters:
@var{width}:@var{height}:@var{x}:@var{y}:@var{color}.

Follows the description of the accepted parameters.

@table @option
@item width, height

Specify the size of the output image with the paddings added. If the
value for @var{width} or @var{height} is 0, the corresponding input size
is used for the output.

The default value of @var{width} and @var{height} is 0.

@item x, y

Specify the offsets where to place the input image in the padded area
with respect to the top/left border of the output image.

The default value of @var{x} and @var{y} is 0.

@item color

Specify the color of the padded area, it can be the name of a color
(case insensitive match) or a 0xRRGGBB[AA] sequence.

The default value of @var{color} is ``black''.

@end table

@section pixdesctest

Pixel format descriptor test filter, mainly useful for internal
testing. The output video should be equal to the input video.

For example:
@example
format=monow, pixdesctest
@end example

can be used to test the monowhite pixel format descriptor definition.

@section rotate

@example
./ffmpeg -i in.avi -vf "rotate=30" out.avi
@end example

Rotate video by a chosen amount in degrees. By default, 45 degrees.

@section scale

Scale the input video to @var{width}:@var{height} and/or convert the image format.

For example the command:

@example
./ffmpeg -i in.avi -vf "scale=200:100" out.avi
@end example

will scale the input video to a size of 200x100.

If the input image format is different from the format requested by
the next filter, the scale filter will convert the input to the
requested format.

If the value for @var{width} or @var{height} is 0, the respective input
size is used for the output.

If the value for @var{width} or @var{height} is -1, the scale filter will
use, for the respective output size, a value that maintains the aspect
ratio of the input image.

The default value of @var{width} and @var{height} is 0.

@section setpts

@example
# Start counting PTS from zero
ffmpeg -i input.avi -vf setpts=PTS-STARTPTS output.avi

# Fast motion
ffmpeg -i input.avi -vf setpts=0.5*PTS output.avi

# Fixed rate 25 fps
ffmpeg -i input.avi -vf setpts=N*AVTB/25 output.avi

# Fixed rate 25 fps with some jitter
ffmpeg -i input.avi -vf 'setpts=AVTB/25*(N+0.05*sin(N*2*PI/25))' output.avi
@end example

Modifies the presentation timestamp (PTS) of the input video.

@section slicify

Pass the images of input video on to next video filter as multiple
slices.

@example
./ffmpeg -i in.avi -vf "slicify=32" out.avi
@end example

The filter accepts the slice height as parameter. If the parameter is
not specified it will use the default value of 16.

Adding this in the beginning of filter chains should make filtering
faster due to better use of the memory cache.

@section split

See the example in the introduction section.
The input video is passed on to two outputs.

@section transpose

@example
./ffmpeg -i in.avi -vf "transpose" out.avi
@end example

Transpose (line => column) input video to next video filter.

@section unsharp

Sharpen or blur the input video.

It accepts the following parameters:
@var{luma_msize_x}:@var{luma_msize_y}:@var{luma_amount}:@var{chroma_msize_x}:@var{chroma_msize_y}:@var{chroma_amount}

Negative values for the amount will blur the input video, while positive
values will sharpen. All parameters are optional and default to the
equivalent of the string '5:5:1.0:0:0:0.0'.

@table @option

@item luma_msize_x
Set the luma matrix horizontal size. It can be an integer between 3
and 13, default value is 5.

@item luma_msize_y
Set the luma matrix vertical size. It can be an integer between 3
and 13, default value is 5.

@item luma_amount
Set the luma effect strength. It can be a float number between -2.0
and 5.0, default value is 1.0.

@item chroma_msize_x
Set the chroma matrix horizontal size. It can be an integer between 3
and 13, default value is 0.

@item chroma_msize_y
Set the chroma matrix vertical size. It can be an integer between 3
and 13, default value is 0.

@item luma_amount
Set the chroma effect strength. It can be a float number between -2.0
and 5.0, default value is 0.0.

@end table

@example
# Strong luma sharpen effect parameters
unsharp=7:7:2.5

# Strong blur of both luma and chroma parameters
unsharp=7:7:-2:7:7:-2

# Use the default values with @command{ffmpeg}
./ffmpeg -i in.avi -vf "unsharp" out.mp4
@end example

@section vflip

Flip the input video vertically.

@example
./ffmpeg -i in.avi -vf "vflip" out.avi
@end example

@c man end VIDEO FILTERS

@chapter Video Sources
@c man begin VIDEO SOURCES

Below is a description of the currently available video sources.

@section buffer

Buffer video frames, and make them available to the filter chain.

This source is mainly intended for a programmatic use, in particular
through the interface defined in @file{libavfilter/vsrc_buffer.h}.

It accepts the following parameters:
@var{width}:@var{height}:@var{pix_fmt_string}

All the parameters need to be explicitely defined.

Follows the list of the accepted parameters.

@table @option

@item width, height
Specify the width and height of the buffered video frames.

@item pix_fmt_string

A string representing the pixel format of the buffered video frames.
It may be a number corresponding to a pixel format, or a pixel format
name.

@end table

For example:
@example
buffer=320:240:yuv410p
@end example

will instruct the source to accept video frames with size 320x240 and
with format "yuv410p". Since the pixel format with name "yuv410p"
corresponds to the number 6 (check the enum PixelFormat definition in
@file{libavutil/pixfmt.h}), this example corresponds to:
@example
buffer=320:240:6
@end example

@section color

Provide an uniformly colored input.

It accepts the following parameters:
@var{color}:@var{frame_size}:@var{frame_rate}

Follows the description of the accepted parameters.

@table @option

@item color
Specify the color of the source. It can be the name of a color (case
insensitive match) or a 0xRRGGBB[AA] sequence, possibly followed by an
alpha specifier. The default value is "black".

@item frame_size
Specify the size of the sourced video, it may be a string of the form
@var{width}x@var{heigth}, or the name of a size abbreviation. The
default value is "320x240".

@item frame_rate
Specify the frame rate of the sourced video, as the number of frames
generated per second. It has to be a string in the format
@var{frame_rate_num}/@var{frame_rate_den}, an integer number, a float
number or a valid video frame rate abbreviation. The default value is
"25".

@end table

For example the following graph description will generate a red source
with an opacity of 0.2, with size "qcif" and a frame rate of 10
frames per second, which will be overlayed over the source connected
to the pad with identifier "in".

@example
"color=red@@0.2:qcif:10 [color]; [in][color] overlay [out]"
@end example

@section movie

The parameters of the movie filter are
@example
 seekpoint in microseconds : string format : string filename
@end example

We can overlay a second movie on top of a main one as in this graph:

@example
 input -----------> deltapts0 --> overlay --> output
                                    ^
 movie --> scale--> deltapts1 ------|
@end example

To do that

@example
ffmpeg -i in.avi -s 240x320 -vf "[in]setpts=PTS-STARTPTS, [T1]overlay=16:16[out]; movie=3200000:avi:in.avi, scale=180:144, setpts=PTS-STARTPTS[T1]" -y out.avi
@end example

@section nullsrc

Null video source, never return images. It is mainly useful as a
template and to be employed in analysis / debugging tools.

It accepts as optional parameter a string of the form
@var{width}:@var{height}, where @var{width} and @var{height} specify the size of
the configured source.

The default values of @var{width} and @var{height} are respectively 352
and 288 (corresponding to the CIF size format).

@c man end VIDEO SOURCES

@chapter Video Sinks
@c man begin VIDEO SINKS

Below is a description of the currently available video sinks.

@section nullsink

Null video sink, do absolutely nothing with the input video. It is
mainly useful as a template and to be employed in analysis / debugging
tools.

@c man end VIDEO SINKS

